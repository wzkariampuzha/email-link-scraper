{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose: Automatically extract links and emails from Google Search\n",
    "1. Search google for links (L.1)\n",
    "2. Search all of those links (L.1) for emails\n",
    "3. Search all of those links (L.1) for links (L.2)\n",
    "4. Search all of those link (L.2) for emails\n",
    "5. Save all links and emails into a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: add support for US data: https://pypi.org/project/us/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "email_re = re.compile(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,4}\")\n",
    "phone_re = re.compile(r\"^(\\+\\d{1,2}\\s)?\\(?\\d{3}\\)?[\\s.-]\\d{3}[\\s.-]\\d{4}$\")\n",
    "from pandas import DataFrame\n",
    "import json\n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(url):\n",
    "    try:\n",
    "        #Open URL\n",
    "        r = requests.get(url)\n",
    "        print(url,'opened')\n",
    "        \n",
    "        #Scrape Emails\n",
    "        emails = {email for email in email_re.findall(r.text) if len(email)<35}\n",
    "        if len(emails) ==0:\n",
    "            emails = {''}\n",
    "        \n",
    "        #Scrape Phone Numbers\n",
    "        phones = {phone for phone in phone_re.findall(r.text)}\n",
    "        if len(phones) == 0:\n",
    "            phones = {''}\n",
    "        \n",
    "        #Scrape Next layer links\n",
    "        links = set()\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        for link in soup.find_all('a'):\n",
    "            l = link.get('href')\n",
    "            if len(l)>10:\n",
    "                if 'tel:' in l:\n",
    "                    #remove the tel:\n",
    "                    phones.add(l[4:])\n",
    "                if 'file' not in l and 'mailto:' not in l and 'who.int' not in l and 'hhs.gov' not in l  and 'hrsa.gov' not in l:\n",
    "                    #If this is a sub-link\n",
    "                    if 'www.' not in l:\n",
    "                        l = url+l[1:]\n",
    "                        links.add(l)\n",
    "                    else:\n",
    "                        links.add(l)\n",
    "        \n",
    "        return emails, phones, links\n",
    "    except:\n",
    "        print(url,\"is unable to be opened.\")\n",
    "        return {''}, {''}, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_csv(searchterm, dictionary):\n",
    "    df = DataFrame.from_dict(dictionary)\n",
    "    save = 'output/'searchterm+'.csv'\n",
    "    df.to_csv(save)\n",
    "    print(save,'SAVED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_link_search(searchterm, max_results=2):\n",
    "    output = {\"Link\":[],\"Email\":[],\"Phone\":[]}\n",
    "    try:\n",
    "        google_results = search(searchterm, num_results=max_results)\n",
    "        for google_link in google_results:\n",
    "            emails, phones, second_links = scrape_url(google_link)\n",
    "            print('first pass',emails, phones, second_links)\n",
    "            \n",
    "            print(if list(emails)[0]!= '' and list(phones)[0]!='')\n",
    "            if list(emails)[0]!= '' and list(phones)[0]!='':\n",
    "                for email, phone in zip_longest(emails, phones):\n",
    "                    output[\"Link\"].append(google_link)\n",
    "                    output[\"Email\"].append(email)\n",
    "                    output[\"Phone\"].append(phone)\n",
    "            \n",
    "            if second_links:\n",
    "                for link in second_links:\n",
    "                    emails, phones, _ = scrape_url(link)\n",
    "                    print('second layer',emails, phones)\n",
    "                    if list(emails)[0]!= '' and list(phones)[0]!='':\n",
    "                        for email, phone in zip_longest(emails, phones):\n",
    "                            output[\"Link\"].append(link)\n",
    "                            output[\"Email\"].append(email)\n",
    "                            output[\"Phone\"].append(phone)\n",
    "                            print(link,'appended')\n",
    "                            print(phone,'appended')\n",
    "                            print(email,'appended')\n",
    "    except:\n",
    "        raise ValueError('Google Search Failed. Input new search term.')\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "searchterm = input()\n",
    "output = email_link_search(searchterm)\n",
    "with open('searched.json', 'w') as f_out:\n",
    "    searched = {}\n",
    "    for k,v in output.items():\n",
    "        #Easiest way to filter a list, even if it gets out of order.\n",
    "        searched[k] = list(set(v))\n",
    "    json.dump(searched, f_out)\n",
    "\n",
    "save_csv(searchterm, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:email-link-extract]",
   "language": "python",
   "name": "conda-env-email-link-extract-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
