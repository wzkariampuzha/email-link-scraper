{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose: Automatically extract links and emails from Google Search\n",
    "1. Search google for links (L.1)\n",
    "2. Search all of those links (L.1) for emails\n",
    "3. Search all of those links (L.1) for links (L.2)\n",
    "4. Search all of those link (L.2) for emails\n",
    "5. Save all links and emails into a csv file such that all of the phone numbers and emails are aligned with the links they were scraped from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: add support for US data: https://pypi.org/project/us/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from pandas import DataFrame\n",
    "import json\n",
    "from itertools import zip_longest\n",
    "import os\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_re1 = re.compile(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,4}\")\n",
    "email_re2 = re.compile(r\"\"\"mailto:(.+?)[\\s?'\"]\"\"\")\n",
    "phone_re1 = re.compile(r\"(?:\\+\\d{1,2}\\s)?\\(?\\d{3}\\)?[\\s.-]\\d{3}[\\s.-]\\d{4}\")\n",
    "phone_re2 = re.compile(r\"\"\"tel:(.+?)[\\s?'\"]\"\"\")\n",
    "excluded_links = {\n",
    "    \".pdf\",\n",
    "    \".png\",\n",
    "    \"file\",\n",
    "    \"mailto:\",\n",
    "    \"cdc.gov\",\n",
    "    \"hhs.gov\",\n",
    "    \"nih.gov\",\n",
    "    \"freeclinics.com\",\n",
    "    \"medicaid.gov\",\n",
    "    \"freeclinicdirectory.org\"\n",
    "}\n",
    "excluded_emails = {\n",
    "    \"support@freeclinics.com\",\n",
    "    \".js\",\n",
    "    \"support@freedentalcare.us\",\n",
    "    \".png\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(url):\n",
    "    try:\n",
    "        # Open URL.\n",
    "        r = requests.get(url)\n",
    "        print(url, \"opened.\")\n",
    "        \n",
    "        # Scrape Emails.\n",
    "        emails = {\n",
    "            email for email in email_re1.findall(r.text)\n",
    "            if len(email) < 35 and\n",
    "            not any(excluded.lower() in email.lower() for excluded in excluded_emails)\n",
    "        }\n",
    "        emails.update({\n",
    "            email for email in email_re2.findall(r.text)\n",
    "            if len(email) < 35 and\n",
    "            not any(excluded.lower() in email.lower() for excluded in excluded_emails)\n",
    "        })\n",
    "        #This is necessary to ensure that the emails, links, and phone numbers are lined up\n",
    "        if len(emails) == 0:\n",
    "            emails = {\"\"}\n",
    "        \n",
    "        # Scrape phone numbers.\n",
    "        phones = {\"\".join(list(filter(str.isdigit, phone))) for phone in phone_re1.findall(r.text)\n",
    "                  if len(\"\".join(list(filter(str.isdigit, phone))))>9}\n",
    "        phones.update({\n",
    "            \"\".join(list(filter(str.isdigit, phone))) for phone in phone_re2.findall(r.text) \n",
    "            if len(\"\".join(list((filter(str.isdigit, phone)))))>9\n",
    "        })\n",
    "        #This is necessary to ensure that the emails, links, and phone numbers are lined up\n",
    "        if len(phones) == 0:\n",
    "            phones = {\"\"}\n",
    "        \n",
    "        # Scrape next layer links.\n",
    "        links = set()\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        for link in soup.find_all(\"a\"):\n",
    "            l = link.get(\"href\")\n",
    "            if len(l) > 10:\n",
    "                if \"tel:\" in l.lower():\n",
    "                    phone = \"\".join(list(filter(str.isdigit, l.replace(\"tel:\", \"\"))))\n",
    "                    if len(phone)>9:\n",
    "                        phones.add()\n",
    "                elif \"mailto:\" in l.lower():\n",
    "                    emails.add(l.lower().replace(\"mailto:\", \"\"))\n",
    "                if not any(excluded_l.lower() in l.lower() for excluded_l in excluded_links):\n",
    "                    # If this is a sub-link.\n",
    "                    if 'www.' not in l and l.lower() != url.lower():\n",
    "                        links.add(urllib.parse.urljoin(url, l).lower())\n",
    "                    else:\n",
    "                        links.add(l.lower())\n",
    "        \n",
    "        return emails, phones, links\n",
    "    except:\n",
    "        print(url, \"is unable to be opened.\")\n",
    "        return {''}, {''}, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9043201234'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = 'tel:9043201234'\n",
    "phone = filter(str.isdigit, l)\n",
    "phone = \"\".join(list(phone))\n",
    "phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_csv(searchterm, dictionary):\n",
    "    df = DataFrame.from_dict(dictionary)\n",
    "    save = \"output/\" + searchterm + \".csv\"\n",
    "    df.to_csv(save)\n",
    "    print(save, \"SAVED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_link_search(searchterm, max_results=25):\n",
    "    output = {\"Link\": [],\"Email\": [],\"Phone\": []}\n",
    "    try:\n",
    "        google_results = search(searchterm, num_results=max_results)\n",
    "        for google_link in google_results:\n",
    "            if not any(ext in google_link for ext in excluded_links):\n",
    "                emails, phones, second_links = scrape_url(google_link)\n",
    "\n",
    "                if list(emails)[0] != \"\" or list(phones)[0] != \"\":\n",
    "                    for email, phone in zip_longest(emails, phones):\n",
    "                        if (email.lower() in output[\"Email\"] and phone in output[\"Phone\"]):\n",
    "                            pass\n",
    "                        else:\n",
    "                            output[\"Link\"].append(google_link)\n",
    "                            #Add these without filtering to ensure that the emails and phone numbers are lined up with links\n",
    "                            output[\"Email\"].append(email)\n",
    "                            output[\"Phone\"].append(phone)\n",
    "\n",
    "                            '''\n",
    "                            if (email is not None and len(email) > 0 and\n",
    "                                \"?\" not in email and\n",
    "                                email.lower() not in output[\"Email\"]):\n",
    "                                output[\"Email\"].append(email.lower())\n",
    "                            if phone is not None and len(phone) > 0:\n",
    "                                output[\"Phone\"].append(phone)\n",
    "                            '''\n",
    "                if second_links:\n",
    "                    for link in second_links:\n",
    "                        emails, phones, _ = scrape_url(link)\n",
    "                        if list(emails)[0] != \"\" or list(phones)[0] != \"\":\n",
    "                            for email, phone in zip_longest(emails, phones):\n",
    "                                if (email in output[\"Email\"] and phone in output[\"Phone\"]):\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    output[\"Link\"].append(link)\n",
    "                                    #Add these without filtering to ensure that the emails and phone numbers are lined up with links\n",
    "                                    output[\"Email\"].append(email)\n",
    "                                    output[\"Phone\"].append(phone)\n",
    "                                '''\n",
    "                                if (email is not None and len(email) > 0 and\n",
    "                                        \"?\" not in email and\n",
    "                                        email.lower() not in output[\"Email\"]):\n",
    "                                    output[\"Email\"].append(email.lower())\n",
    "                                if phone is not None and len(phone) > 0:\n",
    "                                    output[\"Phone\"].append(phone)\n",
    "                                '''\n",
    "    except:\n",
    "        raise ValueError('Google Search Failed. Input new search term.')\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iowa free clinics\n",
      "https://www.fciowa.org/ opened.\n",
      "https://www.fciowa.org/#comp-ky4p0vtt opened.\n",
      "https://www.fciowa.org/contact opened.\n",
      "https://www.fciowa.org/contact is unable to be opened.\n",
      "https://www.fciowa.org/donors opened.\n",
      "https://www.facebook.com/fciowa opened.\n",
      "https://www.fciowa.org/volunteer opened.\n",
      "https://www.fciowa.org/olddonate opened.\n",
      "https://www.fciowa.org/olddonate is unable to be opened.\n",
      "https://www.fciowa.org/board-of-directors opened.\n",
      "https://www.fciowa.org/#comp-jww4y2um opened.\n",
      "https://www.fciowa.org/clinic-details opened.\n"
     ]
    }
   ],
   "source": [
    "# Sample input: free homeless clinic contact info\n",
    "searchterm = input()\n",
    "output = email_link_search(searchterm, max_results=2)\n",
    "if not os.path.exists(\"output\"):\n",
    "    os.mkdir(\"output\")\n",
    "with open('output/searched.json', 'w') as f_out:\n",
    "    searched = {}\n",
    "    for k, v in output.items():\n",
    "        # Easiest way to filter a list, even if it gets out of order.\n",
    "        searched[k] = list(set(v))\n",
    "    json.dump(searched, f_out)\n",
    "\n",
    "# Note: I think I broke the save_csv function because the number of\n",
    "# phones, emails, and links no longer match.\n",
    "save_csv(searchterm, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:email-link-extract]",
   "language": "python",
   "name": "conda-env-email-link-extract-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
